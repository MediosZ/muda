#include <catch2/catch.hpp>
#include <muda/muda.h>
#include <muda/container.h>
#include "../example_common.h"
using namespace muda;
struct KernelATag
{
};
struct KernelBTag
{
};
struct KernelCTag
{
};
struct KernelDTag
{
};
void graph_bindless()
{
    example_desc(
        R"(In this example we use graphManager, bindless viewer and kernel-new to calculate
alloc count, allocate momery and set values in graph (without any host operation),
then copy the values from kernel heap memory to device global memory and finally
to the host memory. 

The cuda graph generated by graphManager is:

                                    (R)
                                     |
                                     A
                                    / \
                                   B   D 
                                   |
                                   C

in which, (R) is the root, and A B C D are kernels. 
NOTE: direct copy from kernel heap memory to host memory is not allowed in cuda!)");


    graphManager gm;

    device_var<int>          alloc_count;
    device_var<int*>         kernel_heap_data;
    device_var<dense1D<int>> bindless;
    device_vector<int>       device_global_data;
    host_vector<int>         host_data;

    launch(1, 1).addNode(
        gm,
        res{alloc_count},
        [alloc_count = make_viewer(alloc_count)] __device__() mutable
        {
            alloc_count = 8;  // calculate the count. (in this case, it is hard coded)
            print("[A] set alloc_count = %d\n", alloc_count);
        },
        KernelATag{});

    launch(1, 1).addNode(
        gm,
        res{res::r, alloc_count, res::w, kernel_heap_data, bindless},
        [alloc_count      = make_viewer(alloc_count),
         kernel_heap_data = make_viewer(kernel_heap_data),
         bindless         = make_viewer(bindless)] __device__() mutable
        {
            some_work();
            // using kernel new to alloc memory on kernel heap
            auto data        = new int[alloc_count];
            kernel_heap_data = data;
            *bindless        = make_dense1D(data, alloc_count);
            print("[B] read alloc_count = %d, alloc kernel heap memory at %p\n",
                  alloc_count,
                  bindless->data());
        },
        KernelBTag{});

    launch(1, 1).addNode(
        gm,
        res{res::w, bindless},
        [bindless = make_viewer(bindless)] __device__() mutable
        {
            auto& viewer = *bindless;
            print("[C] viewer.dim() = %d\n", viewer.dim());
            // set values from 0 -> 7
            for(size_t i = 0; i < viewer.dim(); i++)
                viewer(i) = i;
            print("kernel set values: %d %d %d %d %d %d %d %d\n",
                  viewer(0),
                  viewer(1),
                  viewer(2),
                  viewer(3),
                  viewer(4),
                  viewer(5),
                  viewer(6),
                  viewer(7));
        },
        KernelCTag{});

    launch(1, 1).addNode(
        gm,
        res{res::r, alloc_count},
        [alloc_count = make_viewer(alloc_count)] __device__() mutable
        {
            // do nothing, but we can illustrate the concurrency
            // cuz kernel D may be launched just after kernel A
            // before kernel B and C
            print("[D] read alloc_count = %d, but do nothing\n", alloc_count);
        },
        KernelDTag{});
    auto instance = gm.instantiate();

    stream graph_stream;
    instance->launch(graph_stream);
    launch::wait_device();

    // copy the viewer from device, for it contains the pointer and the size
    dense1D<int> viewer = bindless;
    // resize the container using the kernel calculated size
    device_global_data.resize(viewer.dim());
    // copy from kernel-heap
    thrust::copy_n(thrust::device_pointer_cast(viewer.data()),
                   viewer.dim(),
                   device_global_data.begin());

    // copy from device global memory to host memory
    host_data = device_global_data;

    std::cout << "our kernel heap memory: " << std::hex << viewer.data() << std::endl;
    std::cout << "copy to -> device global memory: " << muda::data(device_global_data)
              << std::endl;
    std::cout << "copy to -> host memory: " << muda::data(host_data) << std::endl;

    std::cout << "host get values: ";
    for(auto& d : host_data)
        std::cout << d << " ";
    std::cout << std::endl;

    on(nullptr)
        .next<launch>(1, 1)
        .apply(
            [kernel_heap_data = make_viewer(kernel_heap_data)] __device__() mutable
            {
                // delete the kernel_heap_data
                delete[] kernel_heap_data;
            })
        .wait();
    std::cout << std::dec;
}

TEST_CASE("graph_bindless", "[graph]")
{
    graph_bindless();
}
